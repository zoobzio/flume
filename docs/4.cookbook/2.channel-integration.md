---
title: Channel Integration
description: Stream processing patterns with Go channels
author: Flume Team
published: 2025-12-03
tags: [Cookbook, Channels, Streaming]
---

# Channel Integration

Flume integrates with Go channels for stream processing patterns.

## Overview

Channels enable:

- **Stream termination** - Pipeline ends by sending to channel
- **Fan-out** - Route to different channels based on conditions
- **Async processing** - Decouple pipeline from downstream processing
- **Integration** - Connect flume to any streaming infrastructure

## Basic Channel Usage

### Register a Channel

```go
outputChannel := make(chan Order, 100)
factory.AddChannel("orders", outputChannel)
```

### Use in Schema

```yaml
type: sequence
children:
  - ref: validate
  - ref: process
  - stream: orders  # Terminal node
```

### Consume the Channel

```go
go func() {
    for order := range outputChannel {
        // Process async
        saveToDatabase(order)
    }
}()
```

## Fan-Out to Multiple Channels

Route to different channels based on conditions:

```go
highPriority := make(chan Order, 50)
lowPriority := make(chan Order, 200)
errors := make(chan Order, 10)

factory.AddChannel("high-priority", highPriority)
factory.AddChannel("low-priority", lowPriority)
factory.AddChannel("errors", errors)

factory.AddCondition(flume.Condition[Order]{
    Name: "priority-level",
    Condition: func(ctx context.Context, o Order) string {
        if o.Total > 1000 {
            return "high"
        }
        return "low"
    },
})
```

```yaml
type: sequence
children:
  - ref: validate
  - type: switch
    condition: priority-level
    routes:
      high:
        stream: high-priority
      low:
        stream: low-priority
    default:
      stream: errors
```

## Stream with Continued Processing

Stream nodes can continue processing after sending:

```yaml
type: sequence
children:
  - ref: validate
  - stream: audit-stream    # Send copy for auditing
    child:
      ref: enrich          # Continue processing
  - ref: finalize
```

This pattern enables:

- **Audit logging** - Capture intermediate states
- **Metrics collection** - Stream to metrics aggregators
- **Event sourcing** - Capture all state changes

## Parallel Streaming

Send to multiple streams in parallel:

```yaml
type: concurrent
children:
  - stream: analytics-stream
  - stream: notification-stream
  - stream: audit-stream
```

All three channels receive cloned data simultaneously.

## Conditional Streaming

Only stream when condition is met:

```yaml
type: filter
predicate: is-notable
then:
  stream: notable-events
else:
  ref: silent-process
```

```go
factory.AddPredicate(flume.Predicate[Event]{
    Name: "is-notable",
    Predicate: func(ctx context.Context, e Event) bool {
        return e.Severity >= SeverityWarning
    },
})
```

## Buffered Processing

Use buffered channels for backpressure:

```go
// Small buffer - immediate backpressure
criticalChannel := make(chan Alert, 10)

// Large buffer - absorb bursts
batchChannel := make(chan Record, 10000)

factory.AddChannel("critical", criticalChannel)
factory.AddChannel("batch", batchChannel)
```

## Worker Pool Pattern

Process channel with worker pool:

```go
outputChannel := make(chan Order, 1000)
factory.AddChannel("orders", outputChannel)

// Start worker pool
for i := 0; i < 10; i++ {
    go func(workerID int) {
        for order := range outputChannel {
            processOrder(workerID, order)
        }
    }(i)
}
```

## Integration with Message Queues

### Kafka

```go
kafkaChannel := make(chan Event, 1000)
factory.AddChannel("kafka-events", kafkaChannel)

go func() {
    producer := kafka.NewProducer(config)
    for event := range kafkaChannel {
        producer.Produce(&kafka.Message{
            TopicPartition: kafka.TopicPartition{Topic: &topic},
            Value:          json.Marshal(event),
        })
    }
}()
```

### RabbitMQ

```go
rabbitChannel := make(chan Message, 500)
factory.AddChannel("rabbit-queue", rabbitChannel)

go func() {
    ch := conn.Channel()
    for msg := range rabbitChannel {
        ch.Publish("", queueName, false, false, amqp.Publishing{
            Body: msg.Body,
        })
    }
}()
```

### Redis Streams

```go
redisChannel := make(chan Entry, 1000)
factory.AddChannel("redis-stream", redisChannel)

go func() {
    for entry := range redisChannel {
        rdb.XAdd(ctx, &redis.XAddArgs{
            Stream: "events",
            Values: entry.ToMap(),
        })
    }
}()
```

## Error Routing

Route errors to dedicated channel:

```yaml
type: fallback
children:
  - type: retry
    attempts: 3
    child:
      ref: process
  - stream: dead-letter-queue
```

```go
dlq := make(chan FailedItem, 100)
factory.AddChannel("dead-letter-queue", dlq)

go func() {
    for item := range dlq {
        logFailure(item)
        alertOps(item)
    }
}()
```

## Real-Time Analytics

Stream events for real-time processing:

```yaml
type: sequence
children:
  - ref: process-transaction
  - type: concurrent
    children:
      - stream: analytics-stream
      - stream: fraud-detection-stream
      - ref: complete-transaction
```

```go
analytics := make(chan Transaction, 10000)
fraud := make(chan Transaction, 1000)

factory.AddChannel("analytics-stream", analytics)
factory.AddChannel("fraud-detection-stream", fraud)

// Analytics aggregator
go func() {
    window := NewTimeWindow(time.Minute)
    for tx := range analytics {
        window.Add(tx)
        if window.Count() >= 1000 {
            publishMetrics(window.Aggregate())
            window.Reset()
        }
    }
}()

// Fraud detector
go func() {
    for tx := range fraud {
        if isSuspicious(tx) {
            alert(tx)
        }
    }
}()
```

## Graceful Shutdown

Handle channel cleanup:

```go
func shutdown(factory *flume.Factory[Order], channels ...chan Order) {
    // Stop accepting new work

    // Wait for in-flight processing
    time.Sleep(gracePeriod)

    // Close channels
    for _, ch := range channels {
        close(ch)
    }

    // Wait for consumers to drain
    wg.Wait()
}
```

## Channel Management

### List Channels

```go
channels := factory.ListChannels()
for _, name := range channels {
    fmt.Println(name)
}
```

### Check Existence

```go
if factory.HasChannel("orders") {
    // Channel exists
}
```

### Remove Channel

```go
removed := factory.RemoveChannel("deprecated-stream")
```

### Get Channel

```go
ch, ok := factory.GetChannel("orders")
if ok {
    // Use channel reference
}
```

## Best Practices

### 1. Size Buffers Appropriately

```go
// Too small - frequent blocking
ch := make(chan Data, 1)

// Too large - memory pressure
ch := make(chan Data, 1000000)

// Right size based on burst patterns
ch := make(chan Data, expectedBurst * 2)
```

### 2. Monitor Channel Health

```go
go func() {
    ticker := time.NewTicker(time.Second)
    for range ticker.C {
        metrics.GaugeChannelLength("orders", len(ordersChannel))
    }
}()
```

### 3. Handle Blocked Channels

```go
// Option 1: Select with timeout
select {
case ch <- item:
    // Sent
case <-time.After(time.Second):
    // Log dropped
    metrics.IncrDropped()
}

// Option 2: Non-blocking with default
select {
case ch <- item:
default:
    // Channel full, handle overflow
}
```

### 4. Document Channel Contracts

```go
// ordersChannel receives validated orders for async processing.
// Buffer: 1000 items
// Consumers: 10 worker goroutines
// Backpressure: Blocks when full
ordersChannel := make(chan Order, 1000)
```

## Next Steps

- [Common Recipes](1.recipes.md) - More patterns
- [Schema Design](../3.guides/1.schema-design.md) - Best practices
- [API Reference](../5.reference/1.api.md) - Channel methods
